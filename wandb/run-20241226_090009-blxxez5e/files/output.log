GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Process Name: MainProcess, PID: 236039, DataIndex: 300
Process Name: MainProcess, PID: 236039, DataIndex: 600
Process Name: MainProcess, PID: 236039, DataIndex: 900
Process Name: MainProcess, PID: 236039, DataIndex: 1200
Process Name: MainProcess, PID: 236039, DataIndex: 1500
Process Name: MainProcess, PID: 236039, DataIndex: 1800
Process Name: MainProcess, PID: 236039, DataIndex: 2100
Process Name: MainProcess, PID: 236039, DataIndex: 2400
Process Name: MainProcess, PID: 236039, DataIndex: 2700
Process Name: MainProcess, PID: 236039, DataIndex: 3000
Process Name: MainProcess, PID: 236039, DataIndex: 3300
Process Name: MainProcess, PID: 236039, DataIndex: 3600
Process Name: MainProcess, PID: 236039, DataIndex: 3900
Process Name: MainProcess, PID: 236039, DataIndex: 4200
Process Name: MainProcess, PID: 236039, DataIndex: 4500
Process Name: MainProcess, PID: 236039, DataIndex: 4800
Process Name: MainProcess, PID: 236039, DataIndex: 5100
Process Name: MainProcess, PID: 236039, DataIndex: 5400
Process Name: MainProcess, PID: 236039, DataIndex: 5700
Process Name: MainProcess, PID: 236039, DataIndex: 6000
Process Name: MainProcess, PID: 236039, DataIndex: 6300
Process Name: MainProcess, PID: 236039, DataIndex: 6600
Process Name: MainProcess, PID: 236039, DataIndex: 6900
Process Name: MainProcess, PID: 236039, DataIndex: 7200
/home/siyao/Apps/anaconda3/envs/miniGrid/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:611: UserWarning: Checkpoint directory /home/siyao/project/rlPractice/DomainGeneralization/modelBased/gen/models/ckpt exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/home/siyao/Apps/anaconda3/envs/miniGrid/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
  | Name          | Type          | Params
------------------------------------------------
0 | generator     | Generator     | 17.6 K
1 | discriminator | Discriminator | 4.9 K
------------------------------------------------
22.5 K    Trainable params
0         Non-trainable params
22.5 K    Total params
0.090     Total estimated model params size (MB)
/home/siyao/Apps/anaconda3/envs/miniGrid/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1927: PossibleUserWarning: The number of training batches (36) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
  rank_zero_warn(
Process Name: MainProcess, PID: 236039, DataIndex: 7500
Process Name: MainProcess, PID: 236039, DataIndex: 7800
Process Name: MainProcess, PID: 236039, DataIndex: 8100
Process Name: MainProcess, PID: 236039, DataIndex: 8400
Process Name: MainProcess, PID: 236039, DataIndex: 8700
Process Name: MainProcess, PID: 236039, DataIndex: 9000
Process Name: MainProcess, PID: 236039, DataIndex: 9300
Process Name: MainProcess, PID: 236039, DataIndex: 9600
Process Name: MainProcess, PID: 236039, DataIndex: 9900
Epoch 0:  30%|██████████████████████████████▉                                                                        | 12/40 [00:00<00:00, 34.11it/s, loss=1.02, v_num=ez5e, g_loss_step=0.663, d_loss_step=1.380]
Metric g_loss improved. New best score: 0.657
Epoch 0, global step 72: 'g_loss' reached 0.65707 (best 0.65707), saving model to '/home/siyao/project/rlPractice/DomainGeneralization/modelBased/gen/models/ckpt/gen-epoch=00-g_loss=0.6571.ckpt' as top 1
Epoch 1, global step 144: 'g_loss' was not in top 1

Epoch 3:  48%|████████████▊              | 19/40 [00:00<00:00, 61.50it/s, loss=1.04, v_num=ez5e, g_loss_step=0.684, d_loss_step=1.390, val_g_loss=0.695, val_d_loss=1.380, g_loss_epoch=0.694, d_loss_epoch=1.380]
Epoch 3, global step 288: 'g_loss' was not in top 1
Epoch 4, global step 360: 'g_loss' was not in top 1
Epoch 6:  90%|████████████████████████▎  | 36/40 [00:00<00:00, 77.47it/s, loss=1.05, v_num=ez5e, g_loss_step=0.718, d_loss_step=1.380, val_g_loss=0.688, val_d_loss=1.380, g_loss_epoch=0.689, d_loss_epoch=1.390]
Validation: 0it [00:00, ?it/s]
Epoch 6, global step 504: 'g_loss' was not in top 1
Epoch 7, global step 576: 'g_loss' was not in top 1

Epoch 8, global step 648: 'g_loss' was not in top 1
Epoch 9, global step 720: 'g_loss' was not in top 1
Epoch 10, global step 792: 'g_loss' was not in top 1

Epoch 12:  78%|████████████████████▏     | 31/40 [00:00<00:00, 71.91it/s, loss=1.04, v_num=ez5e, g_loss_step=0.723, d_loss_step=1.360, val_g_loss=0.705, val_d_loss=1.380, g_loss_epoch=0.689, d_loss_epoch=1.390]
Epoch 12, global step 936: 'g_loss' was not in top 1
Epoch 13, global step 1008: 'g_loss' was not in top 1

Epoch 15:  82%|█████████████████████▍    | 33/40 [00:00<00:00, 75.76it/s, loss=1.03, v_num=ez5e, g_loss_step=0.723, d_loss_step=1.350, val_g_loss=0.724, val_d_loss=1.340, g_loss_epoch=0.727, d_loss_epoch=1.340]
Epoch 15, global step 1152: 'g_loss' was not in top 1
Epoch 16, global step 1224: 'g_loss' was not in top 1
Epoch 18:  90%|███████████████████████▍  | 36/40 [00:00<00:00, 77.41it/s, loss=1.03, v_num=ez5e, g_loss_step=0.745, d_loss_step=1.360, val_g_loss=0.724, val_d_loss=1.340, g_loss_epoch=0.719, d_loss_epoch=1.340]
Validation: 0it [00:00, ?it/s]
Epoch 18, global step 1368: 'g_loss' was not in top 1
Epoch 19, global step 1440: 'g_loss' was not in top 1

Epoch 20, global step 1512: 'g_loss' was not in top 1
Epoch 21, global step 1584: 'g_loss' was not in top 1
Epoch 22, global step 1656: 'g_loss' was not in top 1

Epoch 24:  52%|█████████████▋            | 21/40 [00:00<00:00, 61.66it/s, loss=1.02, v_num=ez5e, g_loss_step=0.738, d_loss_step=1.300, val_g_loss=0.730, val_d_loss=1.310, g_loss_epoch=0.717, d_loss_epoch=1.320]
Epoch 24, global step 1800: 'g_loss' was not in top 1
Epoch 25, global step 1872: 'g_loss' was not in top 1

Epoch 27:  62%|██████████████████▏          | 25/40 [00:00<00:00, 62.45it/s, loss=1, v_num=ez5e, g_loss_step=0.768, d_loss_step=1.240, val_g_loss=0.763, val_d_loss=1.250, g_loss_epoch=0.757, d_loss_epoch=1.260]
Epoch 27, global step 2016: 'g_loss' was not in top 1
Epoch 28, global step 2088: 'g_loss' was not in top 1

Epoch 30:  80%|████████████████████     | 32/40 [00:00<00:00, 67.45it/s, loss=0.985, v_num=ez5e, g_loss_step=0.808, d_loss_step=1.160, val_g_loss=0.808, val_d_loss=1.170, g_loss_epoch=0.789, d_loss_epoch=1.190]
Epoch 30, global step 2232: 'g_loss' was not in top 1
Epoch 32: 100%|██████████████████████████| 40/40 [00:00<00:00, 59.69it/s, loss=0.98, v_num=ez5e, g_loss_step=0.848, d_loss_step=1.150, val_g_loss=0.838, val_d_loss=1.120, g_loss_epoch=0.825, d_loss_epoch=1.140]
Validation DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 387.08it/s]
Epoch 32, global step 2376: 'g_loss' was not in top 1
Epoch 33, global step 2448: 'g_loss' was not in top 1

Epoch 34, global step 2520: 'g_loss' was not in top 1
Epoch 35, global step 2592: 'g_loss' was not in top 1
Epoch 36, global step 2664: 'g_loss' was not in top 1

Epoch 39:   0%|                                  | 0/40 [00:00<?, ?it/s, loss=0.972, v_num=ez5e, g_loss_step=1.060, d_loss_step=0.841, val_g_loss=1.080, val_d_loss=0.877, g_loss_epoch=1.040, d_loss_epoch=0.908]
Epoch 38, global step 2808: 'g_loss' was not in top 1
Epoch 39, global step 2880: 'g_loss' was not in top 1

Epoch 42:   0%|                                  | 0/40 [00:00<?, ?it/s, loss=0.986, v_num=ez5e, g_loss_step=1.130, d_loss_step=0.745, val_g_loss=1.170, val_d_loss=0.783, g_loss_epoch=1.180, d_loss_epoch=0.796]
Epoch 41, global step 3024: 'g_loss' was not in top 1
Epoch 42, global step 3096: 'g_loss' was not in top 1

Epoch 44:  57%|██████████████▉           | 23/40 [00:00<00:00, 62.59it/s, loss=1.02, v_num=ez5e, g_loss_step=1.370, d_loss_step=0.726, val_g_loss=1.340, val_d_loss=0.715, g_loss_epoch=1.280, d_loss_epoch=0.736]
Epoch 44, global step 3240: 'g_loss' was not in top 1
Epoch 45, global step 3312: 'g_loss' was not in top 1

Epoch 47:  62%|████████████████▎         | 25/40 [00:00<00:00, 58.55it/s, loss=1.05, v_num=ez5e, g_loss_step=1.520, d_loss_step=0.622, val_g_loss=1.500, val_d_loss=0.625, g_loss_epoch=1.450, d_loss_epoch=0.647]
Epoch 47, global step 3456: 'g_loss' was not in top 1
Epoch 48, global step 3528: 'g_loss' was not in top 1

Epoch 50:  40%|██████████▍               | 16/40 [00:00<00:00, 46.20it/s, loss=1.12, v_num=ez5e, g_loss_step=1.710, d_loss_step=0.540, val_g_loss=1.680, val_d_loss=0.540, g_loss_epoch=1.630, d_loss_epoch=0.561]
Epoch 50, global step 3672: 'g_loss' was not in top 1

Epoch 53:  60%|███████████████▌          | 24/40 [00:00<00:00, 68.60it/s, loss=1.17, v_num=ez5e, g_loss_step=1.990, d_loss_step=0.474, val_g_loss=1.910, val_d_loss=0.475, g_loss_epoch=1.820, d_loss_epoch=0.490]
Epoch 52, global step 3816: 'g_loss' was not in top 1
Epoch 53, global step 3888: 'g_loss' was not in top 1
Epoch 54, global step 3960: 'g_loss' was not in top 1

Epoch 55: 100%|██████████████████████████| 40/40 [00:00<00:00, 63.10it/s, loss=1.25, v_num=ez5e, g_loss_step=2.240, d_loss_step=0.477, val_g_loss=2.130, val_d_loss=0.403, g_loss_epoch=2.020, d_loss_epoch=0.430]
Epoch 57:  90%|███████████████████████▍  | 36/40 [00:00<00:00, 89.56it/s, loss=1.25, v_num=ez5e, g_loss_step=2.160, d_loss_step=0.317, val_g_loss=2.100, val_d_loss=0.399, g_loss_epoch=2.070, d_loss_epoch=0.408]
