GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/siyao/Apps/anaconda3/envs/miniGrid/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:611: UserWarning: Checkpoint directory /home/siyao/project/rlPractice/DomainGeneralization/modelBased/gen/models/ckpt exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/home/siyao/Apps/anaconda3/envs/miniGrid/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
  | Name          | Type          | Params
------------------------------------------------
0 | generator     | Generator     | 826 K
1 | discriminator | Discriminator | 78.0 K
------------------------------------------------
904 K     Trainable params
0         Non-trainable params
904 K     Total params
3.619     Total estimated model params size (MB)
Process Name: MainProcess, PID: 39962, DataIndex: 300
Process Name: MainProcess, PID: 39962, DataIndex: 600
Process Name: MainProcess, PID: 39962, DataIndex: 900
Sanity Checking DataLoader 0:   0%|                                                   | 0/1 [00:00<?, ?it/s]
/home/siyao/Apps/anaconda3/envs/miniGrid/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1927: PossibleUserWarning: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Epoch 0:  80%|â–ˆâ–ˆâ–| 4/5 [00:01<00:00,  3.25it/s, loss=1.12, v_num=o5vz, g_loss_step=0.486, d_loss_step=1.550]
Validation: 0it [00:00, ?it/s]
Metric g_loss improved. New best score: 0.445
Epoch 0, global step 8: 'g_loss' reached 0.44507 (best 0.44507), saving model to '/home/siyao/project/rlPractice/DomainGeneralization/modelBased/gen/models/ckpt/gen-epoch=00-g_loss=0.4451.ckpt' as top 1
Epoch 1, global step 16: 'g_loss' was not in top 1
Epoch 2, global step 24: 'g_loss' was not in top 1

Epoch 3, global step 32: 'g_loss' was not in top 1
Epoch 4, global step 40: 'g_loss' was not in top 1
Epoch 5, global step 48: 'g_loss' was not in top 1
Epoch 6, global step 56: 'g_loss' was not in top 1

Epoch 11:  80%|â–Š| 4/5 [00:00<00:00, 13.97it/s, loss=1.34, v_num=o5vz, g_loss_step=2.820, d_loss_step=0.233,
Validation: 0it [00:00, ?it/s]
Epoch 8, global step 72: 'g_loss' was not in top 1
Epoch 9, global step 80: 'g_loss' was not in top 1
Epoch 10, global step 88: 'g_loss' was not in top 1

Epoch 11, global step 96: 'g_loss' was not in top 1
Epoch 12, global step 104: 'g_loss' was not in top 1
Epoch 13, global step 112: 'g_loss' was not in top 1
Epoch 14, global step 120: 'g_loss' was not in top 1

Epoch 19:   0%| | 0/5 [00:00<?, ?it/s, loss=1.88, v_num=o5vz, g_loss_step=3.850, d_loss_step=0.0635, val_g_l
Epoch 16, global step 136: 'g_loss' was not in top 1
Epoch 17, global step 144: 'g_loss' was not in top 1

Epoch 23:   0%| | 0/5 [00:00<?, ?it/s, loss=1.91, v_num=o5vz, g_loss_step=3.600, d_loss_step=0.0705, val_g_l
Epoch 19, global step 160: 'g_loss' was not in top 1
Epoch 20, global step 168: 'g_loss' was not in top 1
Epoch 21, global step 176: 'g_loss' was not in top 1
Epoch 26:  80%|â–Š| 4/5 [00:00<00:00, 13.91it/s, loss=2.21, v_num=o5vz, g_loss_step=4.480, d_loss_step=0.0362,
Validation: 0it [00:00, ?it/s]
Epoch 23, global step 192: 'g_loss' was not in top 1
Epoch 24, global step 200: 'g_loss' was not in top 1
Epoch 25, global step 208: 'g_loss' was not in top 1

Epoch 26, global step 216: 'g_loss' was not in top 1
Epoch 27, global step 224: 'g_loss' was not in top 1
Epoch 28, global step 232: 'g_loss' was not in top 1

Epoch 34:   0%| | 0/5 [00:00<?, ?it/s, loss=2.46, v_num=o5vz, g_loss_step=4.940, d_loss_step=0.0226, val_g_l
Epoch 30, global step 248: 'g_loss' was not in top 1
Epoch 31, global step 256: 'g_loss' was not in top 1
Epoch 32, global step 264: 'g_loss' was not in top 1

Epoch 38:   0%| | 0/5 [00:00<?, ?it/s, loss=2.57, v_num=o5vz, g_loss_step=5.170, d_loss_step=0.019, val_g_lo
Epoch 34, global step 280: 'g_loss' was not in top 1
Epoch 35, global step 288: 'g_loss' was not in top 1
Epoch 36, global step 296: 'g_loss' was not in top 1
Epoch 41:  80%|â–Š| 4/5 [00:00<00:00, 13.95it/s, loss=2.65, v_num=o5vz, g_loss_step=5.320, d_loss_step=0.015,
Validation: 0it [00:00, ?it/s]
Epoch 38, global step 312: 'g_loss' was not in top 1
Epoch 39, global step 320: 'g_loss' was not in top 1
Epoch 40, global step 328: 'g_loss' was not in top 1
Epoch 41, global step 336: 'g_loss' was not in top 1
Epoch 42, global step 344: 'g_loss' was not in top 1
Epoch 43, global step 352: 'g_loss' was not in top 1

Epoch 44, global step 360: 'g_loss' was not in top 1
Epoch 45, global step 368: 'g_loss' was not in top 1
Epoch 46, global step 376: 'g_loss' was not in top 1
Epoch 47, global step 384: 'g_loss' was not in top 1

Epoch 49:   0%| | 0/5 [00:00<?, ?it/s, loss=2.78, v_num=o5vz, g_loss_step=5.580, d_loss_step=0.0112, val_g_l
Epoch 49, global step 400: 'g_loss' was not in top 1
Epoch 50, global step 408: 'g_loss' was not in top 1
Epoch 52:  80%|â–Š| 4/5 [00:00<00:00, 12.14it/s, loss=2.84, v_num=o5vz, g_loss_step=5.700, d_loss_step=0.0108,
Validation: 0it [00:00, ?it/s]
Epoch 52, global step 424: 'g_loss' was not in top 1
Epoch 53, global step 432: 'g_loss' was not in top 1
Epoch 54, global step 440: 'g_loss' was not in top 1


Epoch 59:   0%| | 0/5 [00:00<?, ?it/s, loss=2.92, v_num=o5vz, g_loss_step=5.830, d_loss_step=0.00816, val_g_
Epoch 56, global step 456: 'g_loss' was not in top 1
Epoch 57, global step 464: 'g_loss' was not in top 1
Epoch 58, global step 472: 'g_loss' was not in top 1
Epoch 59, global step 480: 'g_loss' was not in top 1
Epoch 60, global step 488: 'g_loss' was not in top 1
Epoch 61:  80%|â–Š| 4/5 [00:00<00:00, 11.49it/s, loss=2.96, v_num=o5vz, g_loss_step=5.950, d_loss_step=0.00814
Validation: 0it [00:00, ?it/s]
Epoch 62, global step 504: 'g_loss' was not in top 1
Epoch 63, global step 512: 'g_loss' was not in top 1
Epoch 64, global step 520: 'g_loss' was not in top 1

Epoch 65, global step 528: 'g_loss' was not in top 1
Epoch 66, global step 536: 'g_loss' was not in top 1
Epoch 67, global step 544: 'g_loss' was not in top 1
Epoch 68:  80%|â–Š| 4/5 [00:00<00:00, 12.73it/s, loss=3.04, v_num=o5vz, g_loss_step=6.130, d_loss_step=0.00678

Validation: 0it [00:00, ?it/s]
Epoch 69, global step 560: 'g_loss' was not in top 1
Epoch 70, global step 568: 'g_loss' was not in top 1
Epoch 75:  80%|â–Š| 4/5 [00:00<00:00, 13.69it/s, loss=3.11, v_num=o5vz, g_loss_step=6.230, d_loss_step=0.0062,
Validation: 0it [00:00, ?it/s]
Epoch 72, global step 584: 'g_loss' was not in top 1
Epoch 73, global step 592: 'g_loss' was not in top 1
Epoch 74, global step 600: 'g_loss' was not in top 1
Epoch 75, global step 608: 'g_loss' was not in top 1
Epoch 76, global step 616: 'g_loss' was not in top 1
Epoch 77, global step 624: 'g_loss' was not in top 1
Epoch 78, global step 632: 'g_loss' was not in top 1

Epoch 79, global step 640: 'g_loss' was not in top 1
Epoch 80, global step 648: 'g_loss' was not in top 1
Epoch 81, global step 656: 'g_loss' was not in top 1

Epoch 87:   0%| | 0/5 [00:00<?, ?it/s, loss=3.21, v_num=o5vz, g_loss_step=6.430, d_loss_step=0.00532, val_g_
Epoch 83, global step 672: 'g_loss' was not in top 1
Epoch 84, global step 680: 'g_loss' was not in top 1
Epoch 85, global step 688: 'g_loss' was not in top 1
Epoch 90:  80%|â–Š| 4/5 [00:00<00:00, 13.35it/s, loss=3.25, v_num=o5vz, g_loss_step=6.500, d_loss_step=0.00465
Validation: 0it [00:00, ?it/s]
Epoch 87, global step 704: 'g_loss' was not in top 1
Epoch 88, global step 712: 'g_loss' was not in top 1
Epoch 89, global step 720: 'g_loss' was not in top 1

Epoch 90, global step 728: 'g_loss' was not in top 1
Epoch 91, global step 736: 'g_loss' was not in top 1
Epoch 92, global step 744: 'g_loss' was not in top 1

Epoch 98:   0%| | 0/5 [00:00<?, ?it/s, loss=3.3, v_num=o5vz, g_loss_step=6.600, d_loss_step=0.00411, val_g_l
Epoch 94, global step 760: 'g_loss' was not in top 1
Epoch 95, global step 768: 'g_loss' was not in top 1
Epoch 96, global step 776: 'g_loss' was not in top 1

Epoch 100: 100%|â–ˆ| 5/5 [00:00<00:00,  9.03it/s, loss=3.32, v_num=o5vz, g_loss_step=6.640, d_loss_step=0.0037
Epoch 98, global step 792: 'g_loss' was not in top 1
Epoch 99, global step 800: 'g_loss' was not in top 1
Monitored metric g_loss did not improve in the last 100 records. Best score: 0.445. Signaling Trainer to stop.
Epoch 100, global step 808: 'g_loss' was not in top 1
[34m[1mwandb[39m[22m: [33mWARNING[39m Saving files without folders. If you want to preserve subdirectories pass base_path to wandb.save, i.e. wandb.save("/mnt/folder/file.h5", base_path="/mnt")